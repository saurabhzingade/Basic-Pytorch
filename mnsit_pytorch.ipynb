{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))\n",
    "\n",
    "inputs = images.view(images.shape[0], -1)\n",
    "\n",
    "w1 = torch.randn(784, 256)\n",
    "b1 = torch.randn(256)\n",
    "\n",
    "w2 = torch.randn(256, 10)\n",
    "b2 = torch.randn(10)\n",
    "\n",
    "h = activation(torch.mm(inputs, w1) + b1)\n",
    "\n",
    "out = torch.mm(h, w2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim=1).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = softmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.0015e-17, 3.4719e-07, 4.9340e-04, 9.3033e-06, 1.3295e-01, 3.8660e-04,\n",
      "         8.6615e-01, 1.1064e-05, 8.8780e-14, 2.0878e-06],\n",
      "        [1.5613e-14, 3.0908e-06, 3.9371e-12, 2.1494e-04, 2.5065e-01, 5.1589e-05,\n",
      "         7.4907e-01, 6.8083e-08, 2.8427e-11, 7.6132e-06],\n",
      "        [3.2493e-19, 1.0037e-03, 3.5544e-13, 3.2077e-06, 1.5283e-03, 2.8456e-04,\n",
      "         9.9718e-01, 6.2784e-10, 6.9782e-18, 4.8319e-07],\n",
      "        [1.6903e-17, 3.6021e-08, 5.3315e-10, 1.0137e-10, 1.4568e-06, 9.9999e-01,\n",
      "         8.0193e-06, 5.2823e-10, 3.2277e-22, 6.5026e-12],\n",
      "        [3.0546e-14, 2.6561e-01, 1.1495e-06, 3.8069e-01, 2.3996e-03, 3.4494e-01,\n",
      "         6.2872e-03, 1.5144e-07, 1.1857e-15, 6.5580e-05],\n",
      "        [9.8648e-15, 1.1888e-01, 1.2061e-08, 3.0657e-08, 6.7915e-06, 7.8702e-01,\n",
      "         9.3465e-02, 5.9837e-05, 1.8661e-13, 5.6005e-04],\n",
      "        [2.1369e-11, 2.8043e-05, 1.6138e-08, 1.4783e-07, 1.0193e-01, 3.6051e-03,\n",
      "         8.9213e-01, 4.5368e-05, 8.6388e-19, 2.2577e-03],\n",
      "        [1.3901e-14, 7.3226e-05, 4.2127e-09, 1.8971e-10, 1.8020e-05, 7.2780e-03,\n",
      "         9.9215e-01, 4.3828e-04, 1.8038e-11, 4.6342e-05],\n",
      "        [9.6860e-17, 1.9802e-02, 3.4209e-12, 1.2265e-08, 9.8016e-01, 3.3500e-05,\n",
      "         2.6379e-06, 8.9605e-13, 3.2558e-12, 5.1789e-12],\n",
      "        [1.0914e-16, 1.6643e-07, 6.1449e-16, 4.2213e-10, 1.9899e-06, 1.3669e-06,\n",
      "         1.0000e+00, 2.8248e-12, 3.2865e-20, 8.1579e-11],\n",
      "        [4.8185e-16, 2.6122e-06, 9.2904e-13, 1.8694e-08, 1.3864e-05, 2.1385e-07,\n",
      "         9.9998e-01, 3.6264e-07, 5.3207e-14, 1.0579e-11],\n",
      "        [3.2514e-16, 5.3756e-03, 1.0315e-10, 1.1143e-03, 9.9350e-01, 2.1706e-06,\n",
      "         5.1340e-06, 1.5284e-07, 1.1752e-15, 6.3202e-07],\n",
      "        [3.5301e-19, 1.1202e-06, 1.1653e-11, 1.6662e-06, 9.4647e-03, 2.1156e-09,\n",
      "         9.9053e-01, 9.0416e-07, 2.1468e-18, 1.3411e-09],\n",
      "        [4.5887e-16, 3.5480e-02, 3.0713e-10, 1.3580e-05, 6.9476e-03, 1.0667e-04,\n",
      "         9.5745e-01, 5.3569e-07, 7.1335e-15, 3.8073e-09],\n",
      "        [6.7238e-16, 1.7016e-05, 6.5985e-08, 4.8177e-06, 8.1419e-01, 1.8347e-01,\n",
      "         2.3203e-03, 5.2873e-07, 3.1263e-15, 5.8573e-07],\n",
      "        [3.0101e-21, 2.0215e-06, 5.6180e-21, 5.4140e-16, 6.9811e-10, 9.9999e-01,\n",
      "         7.6205e-06, 7.9274e-11, 4.6608e-16, 1.4219e-12],\n",
      "        [3.9534e-12, 3.7163e-01, 6.0658e-07, 6.7911e-03, 4.1603e-01, 1.9703e-01,\n",
      "         7.7980e-03, 5.8733e-04, 1.8984e-12, 1.3632e-04],\n",
      "        [8.1210e-12, 9.5438e-01, 2.1846e-14, 1.8095e-06, 1.4664e-04, 5.2471e-04,\n",
      "         5.5021e-03, 1.2234e-07, 2.7511e-14, 3.9443e-02],\n",
      "        [1.1713e-12, 2.2513e-01, 2.0184e-03, 6.1203e-04, 1.1637e-01, 1.1711e-02,\n",
      "         4.5313e-02, 5.9885e-01, 1.1521e-16, 1.3021e-06],\n",
      "        [1.5992e-21, 1.9374e-06, 2.1432e-07, 5.7498e-06, 1.2156e-03, 9.9869e-01,\n",
      "         2.3615e-05, 2.4712e-08, 2.1449e-15, 6.0058e-05],\n",
      "        [4.1472e-22, 1.3978e-08, 4.6940e-15, 1.4368e-11, 5.3452e-12, 1.0000e+00,\n",
      "         5.6321e-08, 2.9081e-12, 6.2446e-21, 4.3364e-14],\n",
      "        [7.8368e-20, 3.6790e-07, 4.5079e-06, 3.7827e-06, 9.1032e-06, 9.9993e-01,\n",
      "         1.7863e-05, 3.5049e-05, 4.5035e-17, 1.2728e-07],\n",
      "        [3.1304e-12, 1.8672e-01, 2.0489e-12, 8.8131e-02, 9.9840e-03, 3.5212e-04,\n",
      "         7.1474e-01, 1.6051e-08, 4.3255e-16, 7.4609e-05],\n",
      "        [1.7339e-15, 2.1200e-04, 2.2835e-13, 1.1652e-07, 9.8941e-09, 9.9826e-01,\n",
      "         1.5275e-03, 7.2781e-08, 1.5036e-15, 1.2323e-10],\n",
      "        [5.7643e-16, 4.1021e-06, 3.0620e-05, 1.9729e-05, 9.9978e-01, 5.9952e-06,\n",
      "         1.5796e-04, 1.6128e-07, 1.4895e-17, 6.8342e-09],\n",
      "        [2.8134e-20, 3.5715e-08, 5.3792e-13, 1.8525e-09, 5.6556e-09, 9.9999e-01,\n",
      "         1.2991e-05, 3.7414e-12, 3.2468e-19, 7.3226e-13],\n",
      "        [5.6594e-15, 6.2048e-06, 3.1562e-14, 2.6216e-08, 2.8479e-10, 1.0330e-05,\n",
      "         9.9998e-01, 1.2691e-08, 1.7310e-20, 2.1338e-09],\n",
      "        [4.3296e-16, 9.6037e-01, 2.8375e-14, 5.2004e-04, 7.2484e-03, 5.0780e-04,\n",
      "         3.1355e-02, 5.5002e-10, 4.3020e-15, 2.4678e-07],\n",
      "        [4.6802e-12, 2.0568e-02, 8.4163e-08, 3.5264e-05, 3.0754e-01, 2.7417e-01,\n",
      "         3.9766e-01, 2.3943e-05, 1.1673e-15, 3.6907e-08],\n",
      "        [9.8108e-17, 9.3951e-03, 6.5543e-12, 3.7226e-05, 2.4519e-08, 9.7743e-01,\n",
      "         1.2996e-02, 5.4767e-09, 3.5450e-17, 1.4308e-04],\n",
      "        [1.1776e-12, 3.2217e-06, 6.3279e-10, 9.7190e-06, 5.9131e-03, 1.3743e-03,\n",
      "         9.9206e-01, 5.7413e-05, 6.4581e-15, 5.7982e-04],\n",
      "        [1.0910e-15, 9.8664e-01, 9.0476e-12, 5.0391e-07, 2.0436e-03, 1.1449e-04,\n",
      "         8.5653e-03, 2.2022e-04, 1.1796e-13, 2.4186e-03],\n",
      "        [1.8221e-18, 3.3414e-07, 2.8475e-15, 2.9840e-11, 5.9555e-11, 1.0000e+00,\n",
      "         2.1202e-07, 1.5173e-11, 6.0506e-16, 3.9125e-10],\n",
      "        [1.2647e-14, 6.3281e-05, 2.4635e-08, 1.8671e-08, 1.2552e-03, 9.9868e-01,\n",
      "         4.3949e-06, 1.1899e-07, 2.1930e-12, 2.1746e-08],\n",
      "        [3.3282e-14, 1.3537e-02, 5.5667e-13, 3.0728e-08, 9.9138e-05, 1.4819e-05,\n",
      "         9.8630e-01, 4.4625e-05, 5.3937e-13, 3.0876e-08],\n",
      "        [1.0563e-15, 4.5832e-07, 1.0722e-12, 8.6838e-06, 2.6931e-08, 7.4969e-01,\n",
      "         2.5030e-01, 2.8633e-07, 1.5564e-16, 2.9228e-07],\n",
      "        [9.1888e-16, 3.0881e-02, 1.2894e-09, 1.3167e-07, 1.1614e-03, 9.3741e-01,\n",
      "         3.0543e-02, 3.6368e-06, 1.6697e-16, 5.0771e-11],\n",
      "        [1.9436e-13, 5.8535e-02, 9.9565e-07, 2.6369e-05, 5.0726e-04, 1.5704e-03,\n",
      "         9.2708e-01, 1.2265e-02, 5.6965e-14, 1.2158e-05],\n",
      "        [6.1161e-10, 9.2523e-03, 7.0626e-05, 1.7106e-04, 9.1006e-01, 7.1941e-06,\n",
      "         8.0054e-02, 2.7124e-04, 7.4539e-16, 1.0835e-04],\n",
      "        [6.8565e-09, 1.8232e-01, 3.8408e-06, 1.3147e-04, 1.4848e-02, 5.5305e-02,\n",
      "         2.2640e-01, 5.0572e-01, 6.2178e-11, 1.5281e-02],\n",
      "        [9.9371e-16, 1.4612e-06, 2.6976e-13, 1.2740e-12, 1.1837e-08, 1.0000e+00,\n",
      "         1.0729e-10, 4.6766e-09, 8.1701e-17, 2.8773e-09],\n",
      "        [9.2236e-13, 7.6333e-01, 5.3151e-12, 1.4327e-04, 4.2214e-02, 1.9431e-01,\n",
      "         1.3188e-08, 7.1737e-11, 4.6101e-16, 2.3111e-07],\n",
      "        [3.0158e-15, 1.5176e-01, 1.5409e-11, 1.6249e-03, 6.4584e-06, 8.4306e-01,\n",
      "         2.7348e-03, 8.6162e-08, 8.0082e-12, 8.1218e-04],\n",
      "        [5.2022e-17, 6.4790e-05, 5.5312e-07, 2.2238e-05, 5.0003e-02, 4.2441e-03,\n",
      "         9.2699e-01, 1.8631e-02, 2.8199e-15, 3.9409e-05],\n",
      "        [1.1886e-15, 1.0816e-07, 1.9015e-10, 5.7208e-10, 1.2616e-07, 9.8087e-01,\n",
      "         1.9131e-02, 1.5233e-08, 2.0113e-22, 5.2410e-09],\n",
      "        [6.5158e-15, 7.2246e-08, 3.6079e-15, 8.6176e-10, 4.4235e-09, 9.8819e-01,\n",
      "         1.1809e-02, 4.3931e-09, 8.2285e-19, 5.6645e-10],\n",
      "        [4.7452e-18, 1.9545e-08, 3.3462e-08, 3.1703e-08, 1.9617e-04, 2.2302e-05,\n",
      "         9.9978e-01, 8.9221e-11, 5.9560e-16, 1.7236e-08],\n",
      "        [1.1878e-16, 5.9114e-07, 4.2644e-08, 8.9556e-07, 2.2839e-07, 9.1974e-07,\n",
      "         9.9999e-01, 2.1701e-10, 1.6920e-17, 2.7008e-06],\n",
      "        [5.8617e-18, 4.8384e-07, 3.7881e-10, 3.4185e-08, 2.3304e-04, 9.9976e-01,\n",
      "         1.2732e-06, 2.9616e-07, 2.1837e-16, 1.0067e-07],\n",
      "        [1.4784e-16, 4.1718e-07, 5.3519e-11, 1.1499e-05, 7.4655e-03, 9.8798e-01,\n",
      "         4.5262e-03, 1.2078e-05, 2.2755e-14, 5.2914e-06],\n",
      "        [6.2245e-12, 5.5979e-03, 5.2940e-09, 3.6077e-04, 9.5587e-03, 8.6956e-01,\n",
      "         1.1480e-01, 1.2019e-04, 1.6181e-12, 5.7403e-08],\n",
      "        [2.4776e-12, 4.4714e-01, 4.2954e-09, 1.3362e-03, 1.0341e-08, 5.4987e-01,\n",
      "         1.6456e-03, 1.2080e-07, 1.6189e-15, 9.3558e-06],\n",
      "        [4.8849e-16, 1.2026e-04, 2.1461e-06, 3.0772e-08, 1.0143e-07, 9.7632e-01,\n",
      "         2.3309e-02, 1.7158e-05, 2.7456e-14, 2.3067e-04],\n",
      "        [6.5391e-14, 2.4033e-02, 5.9105e-11, 6.1681e-07, 3.2419e-03, 2.4133e-03,\n",
      "         9.7016e-01, 1.5648e-04, 3.1389e-17, 3.0392e-11],\n",
      "        [1.1804e-14, 1.0299e-03, 9.6509e-08, 7.5269e-04, 1.1619e-05, 5.8305e-01,\n",
      "         4.1513e-01, 1.0941e-05, 2.1008e-13, 1.3829e-05],\n",
      "        [2.8827e-19, 4.2365e-04, 7.4821e-15, 3.0766e-06, 1.2564e-03, 1.0287e-06,\n",
      "         9.9832e-01, 9.7594e-09, 9.1453e-16, 3.0826e-10],\n",
      "        [1.4173e-16, 2.1481e-06, 4.8367e-20, 3.2620e-12, 1.8828e-10, 6.4727e-09,\n",
      "         1.0000e+00, 2.1622e-10, 7.2075e-21, 2.3098e-10],\n",
      "        [1.3249e-18, 1.9669e-06, 2.0991e-12, 2.4634e-07, 7.1863e-08, 9.9995e-01,\n",
      "         4.7610e-05, 1.6515e-07, 1.1886e-16, 4.2368e-11],\n",
      "        [4.0541e-18, 1.3776e-03, 1.0377e-07, 9.8361e-07, 9.3028e-02, 6.9508e-07,\n",
      "         9.0559e-01, 4.3307e-09, 3.1570e-18, 4.7380e-09],\n",
      "        [1.2094e-20, 1.5980e-05, 2.4577e-13, 7.2134e-09, 5.7880e-07, 9.3130e-03,\n",
      "         9.9067e-01, 3.0434e-08, 3.7542e-18, 2.1860e-06],\n",
      "        [6.1266e-15, 2.7790e-04, 1.1764e-06, 2.4518e-03, 2.8682e-03, 9.9440e-01,\n",
      "         4.0064e-07, 1.8740e-09, 6.7381e-14, 2.5918e-09],\n",
      "        [1.9139e-16, 1.0369e-04, 4.2925e-10, 4.1842e-09, 4.3473e-01, 5.6515e-01,\n",
      "         1.5385e-05, 7.5351e-09, 2.4988e-16, 1.0019e-11],\n",
      "        [1.6447e-17, 1.0909e-03, 2.8962e-09, 9.4869e-09, 2.0965e-03, 3.5089e-02,\n",
      "         9.6172e-01, 5.3977e-10, 2.8137e-13, 8.7179e-12],\n",
      "        [4.4998e-13, 3.7989e-01, 4.0757e-07, 1.4453e-04, 5.2301e-01, 1.2926e-02,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         8.4032e-02, 1.9508e-07, 2.6329e-11, 5.4766e-08]])\n"
     ]
    }
   ],
   "source": [
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist(nn.Module):\n",
    "    def __init__(self):\n",
    "        super.__init__()\n",
    "        self.hidden = nn.Linear(786,256)\n",
    "        self.output = nn.Linear(256,10)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with sigmoid activation\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # Output layer with softmax activation\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mnist(\n",
       "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (hidden2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Mnist(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(784,128)\n",
    "        self.hidden2 = nn.Linear(128,64)\n",
    "        self.out = nn.Linear(64,10)\n",
    "    def forward(self,x):\n",
    "        x = self.hidden1(x)\n",
    "        x=F.relu(x)\n",
    "        x= self.hidden2(x)\n",
    "        x=F.relu(x)\n",
    "        x = self.out(x)\n",
    "        x= F.softmax(x)\n",
    "        return x\n",
    "model = Mnist()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0121, -0.0051, -0.0257,  ...,  0.0130, -0.0155,  0.0188],\n",
      "        [ 0.0131, -0.0117,  0.0114,  ...,  0.0331,  0.0294, -0.0290],\n",
      "        [-0.0239, -0.0206,  0.0020,  ..., -0.0213, -0.0343,  0.0295],\n",
      "        ...,\n",
      "        [-0.0317,  0.0296,  0.0168,  ..., -0.0200, -0.0169,  0.0006],\n",
      "        [-0.0080, -0.0132, -0.0138,  ...,  0.0252, -0.0238,  0.0028],\n",
      "        [-0.0113, -0.0042, -0.0062,  ..., -0.0162, -0.0098, -0.0083]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.3827e-02, -2.5787e-02,  9.1389e-03, -2.6902e-02,  3.0995e-02,\n",
      "         2.9497e-02, -1.6748e-02,  6.8179e-03,  3.5176e-02, -6.6347e-03,\n",
      "        -1.3184e-02,  1.2865e-02, -2.0663e-02, -2.4560e-02, -2.1215e-02,\n",
      "         2.5171e-02, -2.0260e-02, -2.4664e-02,  1.5519e-02,  1.4749e-02,\n",
      "        -5.1517e-03, -2.5748e-02,  2.3329e-02,  1.5682e-02, -1.8678e-02,\n",
      "         1.9442e-02,  1.0726e-02,  1.0355e-02,  2.5185e-02, -2.7092e-02,\n",
      "        -2.9648e-02, -2.6396e-02, -2.2342e-02, -2.6772e-02,  2.3018e-02,\n",
      "        -3.1686e-02, -4.7361e-03, -2.6460e-03,  1.2743e-02,  1.0079e-02,\n",
      "        -4.1302e-03, -2.7841e-02, -1.6358e-02,  1.7928e-03, -4.4634e-03,\n",
      "        -1.1253e-02,  2.3564e-03,  1.5368e-02, -3.3831e-02,  5.8944e-03,\n",
      "        -1.3876e-02, -2.2514e-02,  1.7980e-02,  7.0689e-03,  2.0759e-02,\n",
      "         2.3114e-02,  1.6289e-02, -1.4091e-02,  3.0503e-02,  1.6440e-02,\n",
      "         1.7769e-02,  2.4953e-03, -5.6869e-03,  9.4151e-03,  2.7698e-02,\n",
      "        -3.3579e-02, -3.2652e-02, -4.7519e-03,  3.3683e-03,  1.6368e-02,\n",
      "         1.8946e-02,  2.5729e-02, -2.1185e-02, -3.8049e-03, -2.8596e-02,\n",
      "        -1.3475e-02, -1.0436e-02,  1.8746e-02, -2.4665e-02, -1.7072e-03,\n",
      "        -9.2361e-05, -6.0030e-03, -3.3013e-02, -2.9124e-02,  1.2205e-02,\n",
      "        -2.2673e-02, -1.9687e-02,  3.2184e-02, -3.9239e-03,  1.6977e-02,\n",
      "        -7.3455e-03,  3.0266e-02,  2.2047e-02, -3.3465e-02, -3.5409e-02,\n",
      "         5.5101e-03,  2.9679e-02,  8.6729e-03,  9.3175e-03, -1.5935e-02,\n",
      "        -8.8500e-03,  9.0494e-03,  2.7222e-02,  2.0452e-02, -3.3561e-02,\n",
      "         1.8838e-02,  2.3771e-02, -6.9327e-03, -1.5333e-02, -2.5337e-02,\n",
      "        -1.2282e-02, -3.1978e-02, -1.4124e-02, -3.5088e-03,  2.6434e-02,\n",
      "         5.9015e-03,  1.2631e-02,  1.4303e-02,  1.9410e-02, -5.7442e-03,\n",
      "        -1.3576e-02,  1.3284e-02,  1.1876e-02,  7.0527e-03,  2.5926e-02,\n",
      "         2.7195e-02,  3.2166e-02, -2.5418e-02], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.hidden1.weight)\n",
    "print(model.hidden1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Acer'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
